# -*- coding: utf-8 -*-
"""Final python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gOiPzPWOAnjOhsu27MSCMV8n6VZ-Gxmj

Import labraries
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt
import seaborn as sns
!pip install squarify
import squarify

"""Cleaning process"""

# define a clean_file function that clean one file at the time
def clean_file(filepath: Path, value_col: str) -> pd.DataFrame:
    df = pd.read_csv(filepath)

    # Remove header row from PolicyMap
    df = df.iloc[1:].copy()

    df["GeoID"] = df["GeoID"].astype(str).str.zfill(5)
    df["County"] = df["Geography Name"].str.strip()
    df["time_period"] = df["Data Time Period"]

    df[value_col] = pd.to_numeric(df[value_col], errors="coerce")

    return df[["County", "GeoID", value_col, "time_period"]]

#Create a where to store clean csv
PROC_DIR = Path("Clean Data")
PROC_DIR.mkdir(parents=True, exist_ok=True)

#Cleaning all files using clean_file function

files = {
    "Median Home Value.csv": "Median Home Value",
    "Median Household Income.csv": "Median Household Income",
    "Percent of People in Poverty.csv": "Percent of People in Poverty",
    "Avg. Travel Time to Work.csv": "Avg. Travel Time to Work (in Minutes)",
    "Percent Population in Owner Occupied Housing Units.csv": "Percent Population in Owner Occupied Housing Units",
    "Percent Population with At Least Bachelor's Degree.csv": "Percent Population with At Least Bachelor's Degree",
    "Population.csv": "Population",
}


for fname, value_col in files.items():
    df_clean = clean_file(Path("/content/") / fname, value_col)
    df_clean.to_csv(PROC_DIR / fname.replace(".csv", "_clean.csv"), index=False)

print("Cleaning complete.\n")

"""Data merging"""

# Load all cleaned files into a list of DataFrames
cleaned_dfs = []
for fname in PROC_DIR.iterdir():
    if fname.suffix == '.csv':
        df = pd.read_csv(fname)
        cleaned_dfs.append(df)

# Merge all DataFrames based on 'GeoID', 'County', and 'time_period'
merged_df = cleaned_dfs[0]
for df in cleaned_dfs[1:]:
    merged_df = pd.merge(merged_df, df, on=['GeoID', 'County', 'time_period'], how='inner')

# Rename columns for clarity and consistency with the model
merged_df = merged_df.rename(columns={
    'Median Home Value': 'Median_Home_Value',
    'Median Household Income': 'Median_Household_Income',
    'Percent of People in Poverty': 'Poverty_Rate',
    'Avg. Travel Time to Work (in Minutes)': 'Commute_Time_Min',
    'Percent Population in Owner Occupied Housing Units': 'Homeownership_Rate',
    "Percent Population with At Least Bachelor's Degree": 'Bachelor_Degree_Rate',
    'Population': 'Population'
})

# Display the first few rows of the merged DataFrame
display(merged_df.head())
#Download the merge file
merged_df.to_csv("az_housing_merged.csv", index=False)

"""Linear regression"""

def run_regression(df):
    print("\nRunning Linear Regression...")

    # Keep only numeric columns
    num = df.select_dtypes(include=np.number).dropna()

    # Features (X) and Target (y)
    X = num.drop("Median_Home_Value", axis=1)
    y = num["Median_Home_Value"]

    # Train-test split
    model = LinearRegression().fit(X, y)
    y_pred = model.predict(X)

    print(f"R²: {r2_score(y, y_pred):.4f}")
    print(f"RMSE: {np.sqrt(mean_squared_error(y, y_pred)):.2f}")

    return pd.DataFrame({
        "Feature": X.columns,
        "Coef": model.coef_
    })
run_regression(merged_df)

"""Random forest model"""

def run_random_forest(df):
    print("\nRunning Random Forest Model...")

    # Keep only numeric columns
    model_df = df.select_dtypes(include=['float64', 'int64']).dropna()

    # Define features (X) and target (y)
    X = model_df.drop(columns=["Median_Home_Value"], errors='ignore')
    y = model_df["Median_Home_Value"]

    # Train-test split
    train_X, test_X, train_y, test_y = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    # Model
    rf = RandomForestRegressor(n_estimators=400, random_state=42)
    rf.fit(train_X, train_y)
    y_pred = rf.predict(test_X)

    # Accuracy
    print(f"Random Forest R²: {r2_score(test_y, y_pred):.4f}")

    # Feature importance
    importance_df = pd.DataFrame({
        "Feature": X.columns,
        "Importance": rf.feature_importances_
    })


    return importance_df

run_random_forest(merged_df)

"""Visualizations"""

def run_visuals(df):
    print(" visuals ")

    sns.set_style("whitegrid")
    #Shows how home values compare across counties
    plt.figure(figsize=(6,4))
    plt.plot(df["County"], df["Median_Home_Value"], marker="o", linewidth=2)
    plt.xticks(rotation=90)
    plt.title("Median Home Value by County (Line Chart)")
    plt.tight_layout()
    plt.show()
    #Shows differences in income levels across counties
    plt.figure(figsize=(6,4))
    plt.plot(df["County"], df["Median_Household_Income"], color="green", marker="o")
    plt.xticks(rotation=90)
    plt.title("Median Household Income by County")
    plt.tight_layout()
    plt.show()

run_visuals(merged_df)

def run_visuals(df):
    print(" visuals ")

    # County with a large population
    plt.figure(figsize=(6,6))
    plt.pie(df["Population"], labels=df["County"], autopct="%1.1f%%")
    plt.title("Population Share by County")
    plt.tight_layout()
    plt.show()

run_visuals(merged_df)

def run_visuals(df):
    print(" visuals ")

    # Relation between income and poverty VS home value
    scatter_pairs = [
        ("Median_Household_Income", "Income vs Home Value"),
        ("Poverty_Rate", "Poverty vs Home Value")

    ]

    for col, title in scatter_pairs:

        if col in df.columns and "Median_Home_Value" in df.columns:
            plt.figure(figsize=(6,4))
            sns.scatterplot(x=df[col], y=df["Median_Home_Value"], s=80)
            plt.title(title)
            plt.xlabel(col)
            plt.ylabel("Median Home Value")
            plt.tight_layout()
            plt.show()
        else:
            print(f"Warning: Skipping scatter plot for '{col}' because one or both required columns are missing.")
run_visuals(merged_df)

def run_visuals(df):
    print(" visuals ")

    plt.figure(figsize=(10,8))
    sns.heatmap(
        df.select_dtypes(include=np.number).corr(),
        annot=True, cmap="coolwarm", fmt=".2f"
    )
    plt.title("Correlation Heatmap of Housing Predictors")
    plt.tight_layout()
    plt.show()
run_visuals(merged_df)